{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "178AkewRG1u86LkKd_zbYjmouyiKM0J1U",
      "authorship_tag": "ABX9TyO7t4GpZoCppm5n+aQfjqTV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/FedyaBadyilo/Skin-Cancer-Detection/blob/main/Untitled0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# план\n",
        "\n",
        "1. собрать общий датасет с маской в качестве таргета\n",
        "2. добавть признаки, используя исторические данные и общие данные\n",
        "3. feature ingeneering\n",
        "4. попробовать предсказания на нейронных сетях, используя в качестве батчей каждый отдельный случай\n",
        "5. попробовать пермешивать точки данные перед обучением модели\n",
        "6. попробовать совместить сверточные слои с машинным обучением"
      ],
      "metadata": {
        "id": "h-IFMZWCxt-1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# data import"
      ],
      "metadata": {
        "id": "83nyfWhQ60QT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install rasterio"
      ],
      "metadata": {
        "id": "EW4djBjw3SLM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ad9da36e-8867-4881-f961-dd367020babf"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting rasterio\n",
            "  Downloading rasterio-1.3.11-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (14 kB)\n",
            "Collecting affine (from rasterio)\n",
            "  Downloading affine-2.4.0-py3-none-any.whl.metadata (4.0 kB)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.10/dist-packages (from rasterio) (24.2.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from rasterio) (2024.8.30)\n",
            "Requirement already satisfied: click>=4.0 in /usr/local/lib/python3.10/dist-packages (from rasterio) (8.1.7)\n",
            "Requirement already satisfied: cligj>=0.5 in /usr/local/lib/python3.10/dist-packages (from rasterio) (0.7.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from rasterio) (1.26.4)\n",
            "Collecting snuggs>=1.4.1 (from rasterio)\n",
            "  Downloading snuggs-1.4.7-py3-none-any.whl.metadata (3.4 kB)\n",
            "Requirement already satisfied: click-plugins in /usr/local/lib/python3.10/dist-packages (from rasterio) (1.1.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from rasterio) (71.0.4)\n",
            "Requirement already satisfied: pyparsing>=2.1.6 in /usr/local/lib/python3.10/dist-packages (from snuggs>=1.4.1->rasterio) (3.1.4)\n",
            "Downloading rasterio-1.3.11-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (21.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.7/21.7 MB\u001b[0m \u001b[31m31.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading snuggs-1.4.7-py3-none-any.whl (5.4 kB)\n",
            "Downloading affine-2.4.0-py3-none-any.whl (15 kB)\n",
            "Installing collected packages: snuggs, affine, rasterio\n",
            "Successfully installed affine-2.4.0 rasterio-1.3.11 snuggs-1.4.7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import rasterio\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "from warnings import simplefilter\n",
        "simplefilter(\"ignore\", category=RuntimeWarning)"
      ],
      "metadata": {
        "id": "v0z8VTXOxCc3"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def print_geotiff_info(path):\n",
        "    try:\n",
        "        # Открываем файл\n",
        "        with rasterio.open(path) as src:\n",
        "            # Основные метаданные\n",
        "            print(f\"File Path: {path}\")\n",
        "            print(f\"Driver: {src.driver}\")\n",
        "            print(f\"Width: {src.width}\")\n",
        "            print(f\"Height: {src.height}\")\n",
        "            print(f\"Count (Bands): {src.count}\")\n",
        "            print(f\"CRS: {src.crs}\")\n",
        "            print(f\"Transform: {src.transform}\")\n",
        "            print(f\"Bounding Box: {src.bounds}\")\n",
        "            print(f\"Datum: {src.dtypes}\")\n",
        "\n",
        "            # Информация по каждому каналу\n",
        "            for i in range(1, src.count + 1):\n",
        "                band = src.read(i)\n",
        "                print(f\"\\nBand {i}:\")\n",
        "                print(f\"  Data Type: {src.dtypes[i - 1]}\")\n",
        "                print(f\"  Min Value: {band.min()}\")\n",
        "                print(f\"  Max Value: {band.max()}\")\n",
        "                print(f\"  Mean Value: {band.mean()}\")\n",
        "                print(f\"  Standard Deviation: {band.std()}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f'Error: {e}')\n",
        "\n",
        "\n",
        "\n",
        "# In[5]:\n",
        "\n",
        "def visualize_rgb_geotiff(file_path, r_band, g_band, b_band, ik_band, mask_band):\n",
        "    try:\n",
        "        with rasterio.open(file_path) as src:\n",
        "            num_bands = src.count\n",
        "            print(f\"Number of bands: {num_bands}\")\n",
        "            red = src.read(r_band)  # B02 - Blue\n",
        "            green = src.read(g_band)  # B03 - Green\n",
        "            blue = src.read(b_band)  # B04 - Red\n",
        "            ik = src.read(ik_band)\n",
        "            mask = src.read(mask_band)\n",
        "\n",
        "            photos = [\n",
        "              np.stack([red, green, blue], axis=-1),\n",
        "              np.stack([ik], axis=-1), # Отрисовка ИК-слоя изображения\n",
        "              np.stack([mask], axis=-1)  # Отрисовка маски изображения\n",
        "            ]\n",
        "\n",
        "            for i in range(3):\n",
        "                fig, ax = plt.subplots(figsize=(10, 10))\n",
        "                if i == 0:\n",
        "                    p2 = np.percentile(photos[i], 1)    # Lower cutoff\n",
        "                    p98 = np.percentile(photos[i], 99)  # Upper cutoff\n",
        "\n",
        "                    photos[i] = np.clip(photos[i], p2, p98)\n",
        "                    photos[i] = ((photos[i] - p2) / (p98 - p2)) * 255\n",
        "\n",
        "                photos[i] = photos[i].astype(np.uint8)\n",
        "                ax.imshow(photos[i])\n",
        "                ax.axis('off')\n",
        "                plt.show()\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f'Ошибка: {e}')\n",
        "\n",
        "\n",
        "\n",
        "def get_mask(path, r_band, g_band, b_band, ik_band, mask_band, task='mask'):\n",
        "    try:\n",
        "\n",
        "      # Открываем файл\n",
        "        with rasterio.open(path) as src:\n",
        "            red = src.read(r_band)  # B02 - Blue\n",
        "            green = src.read(g_band)  # B03 - Green\n",
        "            blue = src.read(b_band)  # B04 - Red\n",
        "            ik = src.read(ik_band)\n",
        "            mask = src.read(mask_band)\n",
        "            if task == 'mask':\n",
        "              return mask\n",
        "            elif task == 'ir':\n",
        "              return ik\n",
        "            else:\n",
        "              return np.stack([red, green, blue], axis=-1)\n",
        "            # Основные метаданные\n",
        "            print(f\"File Path: {path}\")\n",
        "            print(f\"Driver: {src.driver}\")\n",
        "            print(f\"Width: {src.width}\")\n",
        "            print(f\"Height: {src.height}\")\n",
        "            print(f\"Count (Bands): {src.count}\")\n",
        "            print(f\"CRS: {src.crs}\")\n",
        "            print(f\"Transform: {src.transform}\")\n",
        "            print(f\"Bounding Box: {src.bounds}\")\n",
        "            print(f\"Datum: {src.dtypes}\")\n",
        "\n",
        "            # Информация по каждому каналу\n",
        "            for i in range(1, src.count + 1):\n",
        "                band = src.read(i)\n",
        "                print(f\"\\nBand {i}:\")\n",
        "                print(f\"  Data Type: {src.dtypes[i - 1]}\")\n",
        "                print(f\"  Min Value: {band.min()}\")\n",
        "                print(f\"  Max Value: {band.max()}\")\n",
        "                print(f\"  Mean Value: {band.mean()}\")\n",
        "                print(f\"  Standard Deviation: {band.std()}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f'Error: {e}')"
      ],
      "metadata": {
        "id": "DfrFuvKvAgY9"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "root_dir = '/content/drive/MyDrive/Colab_Notebooks/forest_fires_hack/minprirody_train/'\n",
        "general_info_path = '/content/drive/MyDrive/Colab_Notebooks/forest_fires_hack/minprirody_train/Реестр пожаров 2015-2021.xls'"
      ],
      "metadata": {
        "id": "1a4hWB9cwWX3"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_gen = pd.read_excel(general_info_path, skiprows=7)"
      ],
      "metadata": {
        "id": "rzAJhI5InufX"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_cols = ['date', 'time', 'name', 'azimuth', 'coordinates', 'wind_speed', 'curr_fire_area', 'overall_fire_area', 'forest_fire_area', 'vegetation_fire_area', 'cause']"
      ],
      "metadata": {
        "id": "FN_A1Q8k5p0Z"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_gen.rename(columns={old_col: new_col for old_col, new_col in zip(df_gen.columns, new_cols)}, inplace=True)"
      ],
      "metadata": {
        "id": "eQMWqiWUzHii"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_gen.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3F5uE1hRxj6n",
        "outputId": "6ead0024-5293-4807-8e14-2e8d8d1d0af6"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1971 entries, 0 to 1970\n",
            "Data columns (total 12 columns):\n",
            " #   Column                Non-Null Count  Dtype  \n",
            "---  ------                --------------  -----  \n",
            " 0   date                  1971 non-null   object \n",
            " 1   time                  1971 non-null   object \n",
            " 2   name                  1967 non-null   object \n",
            " 3   azimuth               1966 non-null   float64\n",
            " 4   coordinates           1971 non-null   object \n",
            " 5   wind_speed            1971 non-null   object \n",
            " 6   curr_fire_area        1902 non-null   float64\n",
            " 7   overall_fire_area     1971 non-null   float64\n",
            " 8   forest_fire_area      1971 non-null   float64\n",
            " 9   vegetation_fire_area  1971 non-null   float64\n",
            " 10  cause                 1971 non-null   float64\n",
            " 11  Unnamed: 11           1971 non-null   object \n",
            "dtypes: float64(6), object(6)\n",
            "memory usage: 184.9+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def min_max_avg(arr):\n",
        "  if not np.any(arr):\n",
        "    return -666, -666, -666\n",
        "  return min(arr), max(arr), np.mean(arr)"
      ],
      "metadata": {
        "id": "Wv0DBXhVawdF"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "coordinates_path = '/content/drive/MyDrive/Colab_Notebooks/forest_fires_hack/pixel_coordinate_mappings.json'"
      ],
      "metadata": {
        "id": "mXRSzDdHQV5D"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "with open(coordinates_path) as f:\n",
        "    json_file = json.load(f)"
      ],
      "metadata": {
        "id": "bwVWqmuBQarj"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(json_file)):\n",
        "  print(np.array(json_file[i][\"20/2021-05-15.tiff\"]).reshape(-1, 2).T.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1rXGelyQR0VO",
        "outputId": "1c92e5a0-1e07-4239-c5f1-78c916934a06"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2, 178182)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def set_dataset(number):\n",
        "  if number > 9:\n",
        "    curr_number = f'{number}'\n",
        "  else:\n",
        "    curr_number = f'0{number}'\n",
        "\n",
        "  curr_dir = root_dir + curr_number\n",
        "  curr_file = f'/{\"\".join(filter(lambda x: False if \"csv\" in x else True, os.listdir(curr_dir)))}'\n",
        "  date =  curr_file.split('.tiff')[0][1:]\n",
        "  number_date = curr_number + curr_file.split('.tiff')[0]\n",
        "  file_name = curr_dir + curr_file\n",
        "\n",
        "  rgb = get_mask(file_name, 1, 2, 3, 4, 5, task = 'img')\n",
        "  mask = get_mask(file_name, 1, 2, 3, 4, 5, task = 'mask')\n",
        "  ir = get_mask(file_name, 1, 2, 3, 4, 5, task = 'ir')\n",
        "  curr_lat, curr_lon = np.array(json_file[0][number_date + '.tiff']).reshape(-1, 2).T\n",
        "\n",
        "  data_dct = {'red': rgb[:, :, 0].flatten(),\n",
        "                      'green': rgb[:, :, 1].flatten(),\n",
        "                      'blue': rgb[:, :, 2].flatten(),\n",
        "                      'info_red': ir.flatten(),\n",
        "                      'mask': mask.flatten(),\n",
        "                      'latitude': curr_lat,\n",
        "                      'longitude': curr_lon\n",
        "                      }\n",
        "\n",
        "  hist_data_curr_file = f'/{\"\".join(filter(lambda x: True if \"csv\" in x else False, os.listdir(curr_dir)))}'\n",
        "  his_data_file = curr_dir + hist_data_curr_file\n",
        "  hist_data = pd.read_csv(his_data_file)\n",
        "\n",
        "  new_hist_cols = ['time', 't_avg', 't_min', 't_max', 'total_precipitation', 'wind_dir', 'wind_speed_hist', 'wind_gust', 'sea_level_pressure']\n",
        "  hist_data.rename(columns={old_col: new_col for old_col, new_col in zip(hist_data.columns, new_hist_cols)}, inplace=True)\n",
        "\n",
        "  df = pd.DataFrame(data_dct)\n",
        "  df['date'] = [number_date] * len(df)\n",
        "\n",
        "  for col in new_hist_cols[1:]:\n",
        "    mi, ma, av = min_max_avg(hist_data[col])\n",
        "    df[f'{col}_min'] = [mi] * len(df)\n",
        "    df[f'{col}_max'] = [ma] * len(df)\n",
        "    df[f'{col}_avg'] = [av] * len(df)\n",
        "\n",
        "  hist_data['time'] = pd.to_datetime(hist_data['time'])\n",
        "  specific_date = pd.to_datetime(date)\n",
        "  end_date = specific_date\n",
        "  last_month = end_date - pd.DateOffset(months=1)\n",
        "  last_last_month = end_date - pd.DateOffset(months=2)\n",
        "\n",
        "  filtered_df = hist_data[(hist_data['time'] >= last_month) & (hist_data['time'] < end_date)]\n",
        "  for col in new_hist_cols[1:]:\n",
        "    mi, ma, av = min_max_avg(filtered_df[col])\n",
        "    df[f'{col}_min_last_month'] = [mi] * len(df)\n",
        "    df[f'{col}_max_last_month'] = [ma] * len(df)\n",
        "    df[f'{col}_avg_last_month'] = [av] * len(df)\n",
        "\n",
        "\n",
        "  FEATURE_INGENEERING = True\n",
        "\n",
        "  if FEATURE_INGENEERING:\n",
        "    # 1. Температурный градиент\n",
        "    df['t_gradient'] = np.mean(hist_data['t_max'] - hist_data['t_min']) * len(df)\n",
        "    # 2. Среднедневная температура\n",
        "    df['t_daily_avg'] = np.mean((hist_data['t_min'] + hist_data['t_max']) / 2) * len(df)\n",
        "    # 3. Усредненные параметры ветра\n",
        "    df['v_avg'] = np.mean((hist_data['wind_speed_hist'] + hist_data['wind_gust']) / 2) * len(df)\n",
        "    # 4. Эффективная скорость ветра\n",
        "    df['v_eff'] = np.mean(np.sqrt(hist_data['wind_speed_hist']**2 + hist_data['wind_gust']**2)) * len(df)\n",
        "    # 5. Относительное давление (пример с высотой 0)\n",
        "\n",
        "    # 6. Вертикальный градиент давления (разница между текущим и предыдущим значением)\n",
        "    df['p_gradient'] = np.mean(hist_data['sea_level_pressure'].diff() * len(df)\n",
        ")\n",
        "    # 7. Интенсивность осадков\n",
        "    df['rain_intensity'] = np.mean(hist_data['total_precipitation'] / (len(hist_data) * 24)) * len(df) #\n",
        "\n",
        "    # 8. Вектор ветра\n",
        "    df['u'] = np.mean(hist_data['wind_speed_hist'] * np.cos(np.radians(hist_data['wind_dir']))) * len(df)\n",
        "    df['v'] = np.mean(hist_data['wind_speed_hist'] * np.sin(np.radians(hist_data['wind_dir']))) * len(df)\n",
        "\n",
        "\n",
        "  # filtered_df_2 = hist_data[(hist_data['time'] >= last_last_month) & (hist_data['time'] < last_month)]\n",
        "  # for col in new_hist_cols[1:]:\n",
        "  #   mi, ma, av = min_max_avg(filtered_df_2[col])\n",
        "  #   df[f'{col}_min_last_last_month'] = [mi] * len(df)\n",
        "  #   df[f'{col}_max_last_last_month'] = [ma] * len(df)\n",
        "  #   df[f'{col}_avg_last_last_month'] = [av] * len(df)\n",
        "\n",
        "\n",
        "  cols = list(set(df.columns) - set(['date']))\n",
        "  df[cols] = df[cols].astype('float16')\n",
        "  return df"
      ],
      "metadata": {
        "id": "b-MmmBdq7kXG"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "  del train_data\n",
        "except:\n",
        "  pass\n",
        "\n",
        "for ind in range(1, 21):\n",
        "  if ind > 1:\n",
        "    train_data = pd.concat([train_data, set_dataset(ind)], ignore_index = True, axis = 0)\n",
        "  else:\n",
        "    train_data = set_dataset(ind)\n",
        "\n",
        "train_data.replace([np.inf, -np.inf], -66666, inplace=True)\n",
        "train_data.fillna(-666, inplace = True);\n",
        "\n",
        "train_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 617
        },
        "id": "Sa_85olh76bE",
        "outputId": "311ed7b1-10e8-4781-d6a0-3b6e73304258"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          red  green  blue  info_red  mask  latitude  longitude  \\\n",
              "0        12.0   14.0  17.0      29.0   0.0   75.1250   55.78125   \n",
              "1        11.0   14.0  14.0      27.0   0.0   75.1250   55.78125   \n",
              "2        11.0   13.0  14.0      27.0   0.0   75.1250   55.78125   \n",
              "3        12.0   14.0  14.0      29.0   0.0   75.1250   55.78125   \n",
              "4        11.0   14.0  13.0      28.0   0.0   75.1250   55.78125   \n",
              "...       ...    ...   ...       ...   ...       ...        ...   \n",
              "5010723   6.0    8.0  13.0      22.0   1.0   71.1875   55.12500   \n",
              "5010724   6.0    8.0  12.0      22.0   1.0   71.1875   55.12500   \n",
              "5010725   5.0    8.0  13.0      21.0   1.0   71.1875   55.12500   \n",
              "5010726   5.0    8.0  13.0      22.0   1.0   71.1875   55.12500   \n",
              "5010727   5.0    9.0  13.0      22.0   1.0   71.1875   55.12500   \n",
              "\n",
              "                  date  t_avg_min  t_avg_max  ...  \\\n",
              "0        01/2021-05-26  -7.300781  20.500000  ...   \n",
              "1        01/2021-05-26  -7.300781  20.500000  ...   \n",
              "2        01/2021-05-26  -7.300781  20.500000  ...   \n",
              "3        01/2021-05-26  -7.300781  20.500000  ...   \n",
              "4        01/2021-05-26  -7.300781  20.500000  ...   \n",
              "...                ...        ...        ...  ...   \n",
              "5010723  20/2021-05-15 -24.796875   7.601562  ...   \n",
              "5010724  20/2021-05-15 -24.796875   7.601562  ...   \n",
              "5010725  20/2021-05-15 -24.796875   7.601562  ...   \n",
              "5010726  20/2021-05-15 -24.796875   7.601562  ...   \n",
              "5010727  20/2021-05-15 -24.796875   7.601562  ...   \n",
              "\n",
              "         sea_level_pressure_max_last_month  sea_level_pressure_avg_last_month  \\\n",
              "0                                   1024.0                             1016.5   \n",
              "1                                   1024.0                             1016.5   \n",
              "2                                   1024.0                             1016.5   \n",
              "3                                   1024.0                             1016.5   \n",
              "4                                   1024.0                             1016.5   \n",
              "...                                    ...                                ...   \n",
              "5010723                             1024.0                             1020.0   \n",
              "5010724                             1024.0                             1020.0   \n",
              "5010725                             1024.0                             1020.0   \n",
              "5010726                             1024.0                             1020.0   \n",
              "5010727                             1024.0                             1020.0   \n",
              "\n",
              "         t_gradient  t_daily_avg  v_avg  v_eff  p_gradient  rain_intensity  \\\n",
              "0          -66666.0     -66666.0 -666.0 -666.0      2788.0       13.390625   \n",
              "1          -66666.0     -66666.0 -666.0 -666.0      2788.0       13.390625   \n",
              "2          -66666.0     -66666.0 -666.0 -666.0      2788.0       13.390625   \n",
              "3          -66666.0     -66666.0 -666.0 -666.0      2788.0       13.390625   \n",
              "4          -66666.0     -66666.0 -666.0 -666.0      2788.0       13.390625   \n",
              "...             ...          ...    ...    ...         ...             ...   \n",
              "5010723    -66666.0     -66666.0 -666.0 -666.0    -11096.0      129.375000   \n",
              "5010724    -66666.0     -66666.0 -666.0 -666.0    -11096.0      129.375000   \n",
              "5010725    -66666.0     -66666.0 -666.0 -666.0    -11096.0      129.375000   \n",
              "5010726    -66666.0     -66666.0 -666.0 -666.0    -11096.0      129.375000   \n",
              "5010727    -66666.0     -66666.0 -666.0 -666.0    -11096.0      129.375000   \n",
              "\n",
              "               u        v  \n",
              "0       -66666.0 -66666.0  \n",
              "1       -66666.0 -66666.0  \n",
              "2       -66666.0 -66666.0  \n",
              "3       -66666.0 -66666.0  \n",
              "4       -66666.0 -66666.0  \n",
              "...          ...      ...  \n",
              "5010723 -66666.0 -66666.0  \n",
              "5010724 -66666.0 -66666.0  \n",
              "5010725 -66666.0 -66666.0  \n",
              "5010726 -66666.0 -66666.0  \n",
              "5010727 -66666.0 -66666.0  \n",
              "\n",
              "[5010728 rows x 64 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-37ecac86-c85a-4dd6-a328-62072f8dc16a\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>red</th>\n",
              "      <th>green</th>\n",
              "      <th>blue</th>\n",
              "      <th>info_red</th>\n",
              "      <th>mask</th>\n",
              "      <th>latitude</th>\n",
              "      <th>longitude</th>\n",
              "      <th>date</th>\n",
              "      <th>t_avg_min</th>\n",
              "      <th>t_avg_max</th>\n",
              "      <th>...</th>\n",
              "      <th>sea_level_pressure_max_last_month</th>\n",
              "      <th>sea_level_pressure_avg_last_month</th>\n",
              "      <th>t_gradient</th>\n",
              "      <th>t_daily_avg</th>\n",
              "      <th>v_avg</th>\n",
              "      <th>v_eff</th>\n",
              "      <th>p_gradient</th>\n",
              "      <th>rain_intensity</th>\n",
              "      <th>u</th>\n",
              "      <th>v</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>12.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>17.0</td>\n",
              "      <td>29.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>75.1250</td>\n",
              "      <td>55.78125</td>\n",
              "      <td>01/2021-05-26</td>\n",
              "      <td>-7.300781</td>\n",
              "      <td>20.500000</td>\n",
              "      <td>...</td>\n",
              "      <td>1024.0</td>\n",
              "      <td>1016.5</td>\n",
              "      <td>-66666.0</td>\n",
              "      <td>-66666.0</td>\n",
              "      <td>-666.0</td>\n",
              "      <td>-666.0</td>\n",
              "      <td>2788.0</td>\n",
              "      <td>13.390625</td>\n",
              "      <td>-66666.0</td>\n",
              "      <td>-66666.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>11.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>27.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>75.1250</td>\n",
              "      <td>55.78125</td>\n",
              "      <td>01/2021-05-26</td>\n",
              "      <td>-7.300781</td>\n",
              "      <td>20.500000</td>\n",
              "      <td>...</td>\n",
              "      <td>1024.0</td>\n",
              "      <td>1016.5</td>\n",
              "      <td>-66666.0</td>\n",
              "      <td>-66666.0</td>\n",
              "      <td>-666.0</td>\n",
              "      <td>-666.0</td>\n",
              "      <td>2788.0</td>\n",
              "      <td>13.390625</td>\n",
              "      <td>-66666.0</td>\n",
              "      <td>-66666.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>11.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>27.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>75.1250</td>\n",
              "      <td>55.78125</td>\n",
              "      <td>01/2021-05-26</td>\n",
              "      <td>-7.300781</td>\n",
              "      <td>20.500000</td>\n",
              "      <td>...</td>\n",
              "      <td>1024.0</td>\n",
              "      <td>1016.5</td>\n",
              "      <td>-66666.0</td>\n",
              "      <td>-66666.0</td>\n",
              "      <td>-666.0</td>\n",
              "      <td>-666.0</td>\n",
              "      <td>2788.0</td>\n",
              "      <td>13.390625</td>\n",
              "      <td>-66666.0</td>\n",
              "      <td>-66666.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>12.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>29.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>75.1250</td>\n",
              "      <td>55.78125</td>\n",
              "      <td>01/2021-05-26</td>\n",
              "      <td>-7.300781</td>\n",
              "      <td>20.500000</td>\n",
              "      <td>...</td>\n",
              "      <td>1024.0</td>\n",
              "      <td>1016.5</td>\n",
              "      <td>-66666.0</td>\n",
              "      <td>-66666.0</td>\n",
              "      <td>-666.0</td>\n",
              "      <td>-666.0</td>\n",
              "      <td>2788.0</td>\n",
              "      <td>13.390625</td>\n",
              "      <td>-66666.0</td>\n",
              "      <td>-66666.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>11.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>28.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>75.1250</td>\n",
              "      <td>55.78125</td>\n",
              "      <td>01/2021-05-26</td>\n",
              "      <td>-7.300781</td>\n",
              "      <td>20.500000</td>\n",
              "      <td>...</td>\n",
              "      <td>1024.0</td>\n",
              "      <td>1016.5</td>\n",
              "      <td>-66666.0</td>\n",
              "      <td>-66666.0</td>\n",
              "      <td>-666.0</td>\n",
              "      <td>-666.0</td>\n",
              "      <td>2788.0</td>\n",
              "      <td>13.390625</td>\n",
              "      <td>-66666.0</td>\n",
              "      <td>-66666.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5010723</th>\n",
              "      <td>6.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>71.1875</td>\n",
              "      <td>55.12500</td>\n",
              "      <td>20/2021-05-15</td>\n",
              "      <td>-24.796875</td>\n",
              "      <td>7.601562</td>\n",
              "      <td>...</td>\n",
              "      <td>1024.0</td>\n",
              "      <td>1020.0</td>\n",
              "      <td>-66666.0</td>\n",
              "      <td>-66666.0</td>\n",
              "      <td>-666.0</td>\n",
              "      <td>-666.0</td>\n",
              "      <td>-11096.0</td>\n",
              "      <td>129.375000</td>\n",
              "      <td>-66666.0</td>\n",
              "      <td>-66666.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5010724</th>\n",
              "      <td>6.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>71.1875</td>\n",
              "      <td>55.12500</td>\n",
              "      <td>20/2021-05-15</td>\n",
              "      <td>-24.796875</td>\n",
              "      <td>7.601562</td>\n",
              "      <td>...</td>\n",
              "      <td>1024.0</td>\n",
              "      <td>1020.0</td>\n",
              "      <td>-66666.0</td>\n",
              "      <td>-66666.0</td>\n",
              "      <td>-666.0</td>\n",
              "      <td>-666.0</td>\n",
              "      <td>-11096.0</td>\n",
              "      <td>129.375000</td>\n",
              "      <td>-66666.0</td>\n",
              "      <td>-66666.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5010725</th>\n",
              "      <td>5.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>21.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>71.1875</td>\n",
              "      <td>55.12500</td>\n",
              "      <td>20/2021-05-15</td>\n",
              "      <td>-24.796875</td>\n",
              "      <td>7.601562</td>\n",
              "      <td>...</td>\n",
              "      <td>1024.0</td>\n",
              "      <td>1020.0</td>\n",
              "      <td>-66666.0</td>\n",
              "      <td>-66666.0</td>\n",
              "      <td>-666.0</td>\n",
              "      <td>-666.0</td>\n",
              "      <td>-11096.0</td>\n",
              "      <td>129.375000</td>\n",
              "      <td>-66666.0</td>\n",
              "      <td>-66666.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5010726</th>\n",
              "      <td>5.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>71.1875</td>\n",
              "      <td>55.12500</td>\n",
              "      <td>20/2021-05-15</td>\n",
              "      <td>-24.796875</td>\n",
              "      <td>7.601562</td>\n",
              "      <td>...</td>\n",
              "      <td>1024.0</td>\n",
              "      <td>1020.0</td>\n",
              "      <td>-66666.0</td>\n",
              "      <td>-66666.0</td>\n",
              "      <td>-666.0</td>\n",
              "      <td>-666.0</td>\n",
              "      <td>-11096.0</td>\n",
              "      <td>129.375000</td>\n",
              "      <td>-66666.0</td>\n",
              "      <td>-66666.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5010727</th>\n",
              "      <td>5.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>71.1875</td>\n",
              "      <td>55.12500</td>\n",
              "      <td>20/2021-05-15</td>\n",
              "      <td>-24.796875</td>\n",
              "      <td>7.601562</td>\n",
              "      <td>...</td>\n",
              "      <td>1024.0</td>\n",
              "      <td>1020.0</td>\n",
              "      <td>-66666.0</td>\n",
              "      <td>-66666.0</td>\n",
              "      <td>-666.0</td>\n",
              "      <td>-666.0</td>\n",
              "      <td>-11096.0</td>\n",
              "      <td>129.375000</td>\n",
              "      <td>-66666.0</td>\n",
              "      <td>-66666.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5010728 rows × 64 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-37ecac86-c85a-4dd6-a328-62072f8dc16a')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-37ecac86-c85a-4dd6-a328-62072f8dc16a button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-37ecac86-c85a-4dd6-a328-62072f8dc16a');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-24eb415a-f684-4ef2-b2f7-31bd1c8d51c7\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-24eb415a-f684-4ef2-b2f7-31bd1c8d51c7')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-24eb415a-f684-4ef2-b2f7-31bd1c8d51c7 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "train_data"
            }
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# train_data.to_csv('/content/drive/MyDrive/Colab_Notebooks/forest_fires_hack/train_data')"
      ],
      "metadata": {
        "id": "ZMaImZA0gfff"
      },
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "\n",
        "url = \"https://weatherapi-com.p.rapidapi.com/current.json\"\n",
        "\n",
        "querystring = {\"q\":f\"{lat}, {lon}\"}\n",
        "\n",
        "headers = {\n",
        "\t\"x-rapidapi-key\": \"2cb2c64b1cmshfc30b41f0cfc97ap170310jsn734cc4d88d58\",\n",
        "\t\"x-rapidapi-host\": \"weatherapi-com.p.rapidapi.com\"\n",
        "}\n",
        "\n",
        "response = requests.get(url, headers=headers, params=querystring)\n",
        "\n",
        "print(response.json())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6md4OGnzOw9v",
        "outputId": "267df6fc-dfff-4361-f41d-a1d79642f92f"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'location': {'name': 'Boston', 'region': 'Lincolnshire', 'country': 'United Kingdom', 'lat': 53.1, 'lon': -0.13, 'tz_id': 'Europe/London', 'localtime_epoch': 1725742119, 'localtime': '2024-09-07 21:48'}, 'current': {'last_updated_epoch': 1725741900, 'last_updated': '2024-09-07 21:45', 'temp_c': 18.2, 'temp_f': 64.8, 'is_day': 0, 'condition': {'text': 'Mist', 'icon': '//cdn.weatherapi.com/weather/64x64/night/143.png', 'code': 1030}, 'wind_mph': 5.6, 'wind_kph': 9.0, 'wind_degree': 50, 'wind_dir': 'NE', 'pressure_mb': 1008.0, 'pressure_in': 29.77, 'precip_mm': 0.0, 'precip_in': 0.0, 'humidity': 88, 'cloud': 50, 'feelslike_c': 18.2, 'feelslike_f': 64.8, 'windchill_c': 16.2, 'windchill_f': 61.1, 'heatindex_c': 16.2, 'heatindex_f': 61.1, 'dewpoint_c': 15.2, 'dewpoint_f': 59.4, 'vis_km': 6.0, 'vis_miles': 3.0, 'uv': 1.0, 'gust_mph': 12.8, 'gust_kph': 20.6}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_cols = list(filter(lambda x: False if x == 'date' or x == 'mask' else True, train_data.columns))\n",
        "target_col = 'mask'\n",
        "date_col = 'date'\n",
        "groups = 'date'"
      ],
      "metadata": {
        "id": "OZS15sOj8TE2"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ml approach"
      ],
      "metadata": {
        "id": "mSCJA-AhAOn7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install catboost; pip install optuna; pip install dask[dataframe]; pip install shap"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xm1FC4QhgTXZ",
        "outputId": "290f49f6-1388-46ef-a3ad-ea494f95c55a"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting catboost\n",
            "  Downloading catboost-1.2.7-cp310-cp310-manylinux2014_x86_64.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.10/dist-packages (from catboost) (0.20.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from catboost) (3.7.1)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.10/dist-packages (from catboost) (1.26.4)\n",
            "Requirement already satisfied: pandas>=0.24 in /usr/local/lib/python3.10/dist-packages (from catboost) (2.1.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from catboost) (1.13.1)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.10/dist-packages (from catboost) (5.15.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from catboost) (1.16.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2024.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (1.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (4.53.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (24.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (3.1.4)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly->catboost) (9.0.0)\n",
            "Downloading catboost-1.2.7-cp310-cp310-manylinux2014_x86_64.whl (98.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.7/98.7 MB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: catboost\n",
            "Successfully installed catboost-1.2.7\n",
            "Collecting optuna\n",
            "  Downloading optuna-4.0.0-py3-none-any.whl.metadata (16 kB)\n",
            "Collecting alembic>=1.5.0 (from optuna)\n",
            "  Downloading alembic-1.13.2-py3-none-any.whl.metadata (7.4 kB)\n",
            "Collecting colorlog (from optuna)\n",
            "  Downloading colorlog-6.8.2-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from optuna) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (24.1)\n",
            "Requirement already satisfied: sqlalchemy>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (2.0.32)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from optuna) (4.66.5)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from optuna) (6.0.2)\n",
            "Collecting Mako (from alembic>=1.5.0->optuna)\n",
            "  Downloading Mako-1.3.5-py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: typing-extensions>=4 in /usr/local/lib/python3.10/dist-packages (from alembic>=1.5.0->optuna) (4.12.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy>=1.3.0->optuna) (3.0.3)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.10/dist-packages (from Mako->alembic>=1.5.0->optuna) (2.1.5)\n",
            "Downloading optuna-4.0.0-py3-none-any.whl (362 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m362.8/362.8 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading alembic-1.13.2-py3-none-any.whl (232 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.0/233.0 kB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading colorlog-6.8.2-py3-none-any.whl (11 kB)\n",
            "Downloading Mako-1.3.5-py3-none-any.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.6/78.6 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: Mako, colorlog, alembic, optuna\n",
            "Successfully installed Mako-1.3.5 alembic-1.13.2 colorlog-6.8.2 optuna-4.0.0\n",
            "Requirement already satisfied: dask[dataframe] in /usr/local/lib/python3.10/dist-packages (2024.7.1)\n",
            "Requirement already satisfied: click>=8.1 in /usr/local/lib/python3.10/dist-packages (from dask[dataframe]) (8.1.7)\n",
            "Requirement already satisfied: cloudpickle>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from dask[dataframe]) (2.2.1)\n",
            "Requirement already satisfied: fsspec>=2021.09.0 in /usr/local/lib/python3.10/dist-packages (from dask[dataframe]) (2024.6.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from dask[dataframe]) (24.1)\n",
            "Requirement already satisfied: partd>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from dask[dataframe]) (1.4.2)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from dask[dataframe]) (6.0.2)\n",
            "Requirement already satisfied: toolz>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from dask[dataframe]) (0.12.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.13.0 in /usr/local/lib/python3.10/dist-packages (from dask[dataframe]) (8.4.0)\n",
            "Requirement already satisfied: pandas>=2.0 in /usr/local/lib/python3.10/dist-packages (from dask[dataframe]) (2.1.4)\n",
            "Collecting dask-expr<1.2,>=1.1 (from dask[dataframe])\n",
            "  Downloading dask_expr-1.1.13-py3-none-any.whl.metadata (2.5 kB)\n",
            "INFO: pip is looking at multiple versions of dask-expr to determine which version is compatible with other requirements. This could take a while.\n",
            "  Downloading dask_expr-1.1.12-py3-none-any.whl.metadata (2.5 kB)\n",
            "  Downloading dask_expr-1.1.11-py3-none-any.whl.metadata (2.5 kB)\n",
            "  Downloading dask_expr-1.1.10-py3-none-any.whl.metadata (2.5 kB)\n",
            "  Downloading dask_expr-1.1.9-py3-none-any.whl.metadata (2.5 kB)\n",
            "Requirement already satisfied: pyarrow>=7.0.0 in /usr/local/lib/python3.10/dist-packages (from dask-expr<1.2,>=1.1->dask[dataframe]) (14.0.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata>=4.13.0->dask[dataframe]) (3.20.1)\n",
            "Requirement already satisfied: numpy<2,>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from pandas>=2.0->dask[dataframe]) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=2.0->dask[dataframe]) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=2.0->dask[dataframe]) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=2.0->dask[dataframe]) (2024.1)\n",
            "Requirement already satisfied: locket in /usr/local/lib/python3.10/dist-packages (from partd>=1.4.0->dask[dataframe]) (1.0.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas>=2.0->dask[dataframe]) (1.16.0)\n",
            "Downloading dask_expr-1.1.9-py3-none-any.whl (241 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m241.9/241.9 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: dask-expr\n",
            "Successfully installed dask-expr-1.1.9\n",
            "Collecting shap\n",
            "  Downloading shap-0.46.0-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (24 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from shap) (1.26.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from shap) (1.13.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from shap) (1.3.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from shap) (2.1.4)\n",
            "Requirement already satisfied: tqdm>=4.27.0 in /usr/local/lib/python3.10/dist-packages (from shap) (4.66.5)\n",
            "Requirement already satisfied: packaging>20.9 in /usr/local/lib/python3.10/dist-packages (from shap) (24.1)\n",
            "Collecting slicer==0.0.8 (from shap)\n",
            "  Downloading slicer-0.0.8-py3-none-any.whl.metadata (4.0 kB)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (from shap) (0.60.0)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.10/dist-packages (from shap) (2.2.1)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba->shap) (0.43.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->shap) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->shap) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->shap) (2024.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->shap) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->shap) (3.5.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->shap) (1.16.0)\n",
            "Downloading shap-0.46.0-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (540 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m540.1/540.1 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading slicer-0.0.8-py3-none-any.whl (15 kB)\n",
            "Installing collected packages: slicer, shap\n",
            "Successfully installed shap-0.46.0 slicer-0.0.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import StratifiedGroupKFold, cross_val_score, train_test_split, cross_validate\n",
        "from sklearn.metrics import f1_score, matthews_corrcoef\n",
        "from sklearn.preprocessing import OneHotEncoder, LabelEncoder, StandardScaler\n",
        "from sklearn.pipeline import make_pipeline\n",
        "\n",
        "from xgboost import XGBClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "from catboost import CatBoostClassifier, Pool\n",
        "\n",
        "import optuna"
      ],
      "metadata": {
        "id": "iq6FTTBD1nKo"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def custom_data_loader(X, y):\n",
        "#   data = pd.concat([X, y], axis = 1)\n",
        "#   unique_dates = data['date'].unique()\n",
        "\n",
        "#   batches = []\n",
        "#   for i in range(len(unique_dates)):\n",
        "#     batches.append((data[data['date'] == unique_dates[i]].drop([target_col], axis = 1).values, data[data['date'] == unique_dates[i]][target_col].values.ravel()))\n",
        "\n",
        "#   return batches\n",
        "\n",
        "# train_dl = custom_data_loader(X_train, y_train)"
      ],
      "metadata": {
        "id": "K684KW5jWmIy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# for x_batch, y_batch in train_dl:\n",
        "#   print(x_batch.shape, y_batch.shape)\n"
      ],
      "metadata": {
        "id": "iIqdlBGwMExl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gc\n",
        "\n",
        "gc.collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MYtmPAbxikEY",
        "outputId": "1074fafe-c759-481f-ff8f-1787c272362f"
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "760"
            ]
          },
          "metadata": {},
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(train_data[num_cols], train_data[target_col], random_state = 42, test_size = 0.4)\n",
        "X_test, X_val, y_test, y_val = train_test_split(X_test, y_test, test_size = .5)"
      ],
      "metadata": {
        "id": "iPlRK9VRmp4f"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for model in [\n",
        "              LGBMClassifier(),\n",
        "              XGBClassifier()]:\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_val)\n",
        "    print(matthews_corrcoef(y_val, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eBL2mJYn_Re4",
        "outputId": "19d04723-55d3-4a58-ba95-9f4de18ecd0e"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 148884, number of negative: 2857552\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.473598 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1252\n",
            "[LightGBM] [Info] Number of data points in the train set: 3006436, number of used features: 54\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.049522 -> initscore=-2.954553\n",
            "[LightGBM] [Info] Start training from score -2.954553\n",
            "0.5139701425629779\n",
            "0.540467525306794\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sorted(list(zip(num_cols, model.feature_importances_)), key = lambda x: x[1], reverse = True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C9vX7a6seaMR",
        "outputId": "a7f54574-f392-4e69-cb23-ba0d472dc799"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('total_precipitation_avg_last_month', 0.3813037),\n",
              " ('total_precipitation_max_last_month', 0.17081237),\n",
              " ('t_max_avg_last_month', 0.12591946),\n",
              " ('t_avg_min_last_month', 0.047218792),\n",
              " ('wind_speed_hist_avg', 0.04474059),\n",
              " ('latitude', 0.023847276),\n",
              " ('t_avg_avg', 0.018727954),\n",
              " ('wind_dir_max', 0.017762804),\n",
              " ('t_avg_min', 0.016339304),\n",
              " ('red', 0.011789361),\n",
              " ('t_avg_max', 0.011589689),\n",
              " ('longitude', 0.0101243025),\n",
              " ('total_precipitation_max', 0.009878924),\n",
              " ('p_gradient', 0.008591981),\n",
              " ('blue', 0.008502832),\n",
              " ('rain_intensity', 0.008339441),\n",
              " ('green', 0.0069074864),\n",
              " ('t_max_max', 0.006579744),\n",
              " ('wind_dir_min_last_month', 0.005797334),\n",
              " ('wind_speed_hist_avg_last_month', 0.005510876),\n",
              " ('sea_level_pressure_avg', 0.005189037),\n",
              " ('info_red', 0.004905478),\n",
              " ('total_precipitation_avg', 0.004420612),\n",
              " ('t_max_min', 0.0042112786),\n",
              " ('wind_dir_max_last_month', 0.0038148814),\n",
              " ('sea_level_pressure_max_last_month', 0.0033260973),\n",
              " ('sea_level_pressure_max', 0.0030651568),\n",
              " ('t_avg_avg_last_month', 0.0027685014),\n",
              " ('t_max_min_last_month', 0.0027144414),\n",
              " ('total_precipitation_min_last_month', 0.0026062771),\n",
              " ('wind_dir_avg_last_month', 0.0025227342),\n",
              " ('sea_level_pressure_min', 0.0024479108),\n",
              " ('t_min_max', 0.0022907774),\n",
              " ('t_avg_max_last_month', 0.0021942998),\n",
              " ('u', 0.0017898936),\n",
              " ('t_min_min', 0.0017338886),\n",
              " ('t_min_avg_last_month', 0.0016589451),\n",
              " ('t_min_max_last_month', 0.0015166989),\n",
              " ('wind_dir_avg', 0.0014765499),\n",
              " ('t_daily_avg', 0.0010756978),\n",
              " ('wind_speed_hist_max', 0.0009283579),\n",
              " ('t_min_min_last_month', 0.00080547394),\n",
              " ('wind_dir_min', 0.0007050183),\n",
              " ('sea_level_pressure_min_last_month', 0.0006865785),\n",
              " ('sea_level_pressure_avg_last_month', 0.00046954607),\n",
              " ('wind_speed_hist_min_last_month', 0.00039170939),\n",
              " ('t_min_avg', 0.0),\n",
              " ('t_max_avg', 0.0),\n",
              " ('total_precipitation_min', 0.0),\n",
              " ('wind_speed_hist_min', 0.0),\n",
              " ('wind_gust_min', 0.0),\n",
              " ('wind_gust_max', 0.0),\n",
              " ('wind_gust_avg', 0.0),\n",
              " ('t_max_max_last_month', 0.0),\n",
              " ('wind_speed_hist_max_last_month', 0.0),\n",
              " ('wind_gust_min_last_month', 0.0),\n",
              " ('wind_gust_max_last_month', 0.0),\n",
              " ('wind_gust_avg_last_month', 0.0),\n",
              " ('t_gradient', 0.0),\n",
              " ('v_avg', 0.0),\n",
              " ('v_eff', 0.0),\n",
              " ('v', 0.0)]"
            ]
          },
          "metadata": {},
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def objective_lgb(trial):\n",
        "    params = {\n",
        "        'objective': 'binary',\n",
        "        'metric': 'binary_logloss',\n",
        "        'num_leaves': trial.suggest_int('num_leaves', 20, 150),\n",
        "        'max_depth': trial.suggest_int('max_depth', -1, 30),\n",
        "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.1),\n",
        "        'n_estimators': trial.suggest_int('n_estimators', 20, 100),\n",
        "        'subsample': trial.suggest_float('subsample', 0.5, 1.0),\n",
        "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),\n",
        "    }\n",
        "\n",
        "    model = LGBMClassifier(**params)\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    preds = model.predict(X_test)\n",
        "    mcc = matthews_corrcoef(y_test, preds)\n",
        "    return mcc\n",
        "\n",
        "# Оптимизация гиперпараметров LightGBM\n",
        "lgb_study = optuna.create_study(direction='maximize')\n",
        "lgb_study.optimize(objective_lgb, n_trials=50)\n",
        "\n",
        "print(\"Best parameters for LightGBM:\", lgb_study.best_params)\n",
        "print(\"Best MCC score for LightGBM:\", lgb_study.best_value)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DFbrGdbnlpD9",
        "outputId": "cdcb210f-bf1a-4e58-cc29-d11c6550ccdc"
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-09-07 22:04:11,266] A new study created in memory with name: no-name-d3ea0806-2e7e-4ab6-938d-c08ee0d101d9\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 148884, number of negative: 2857552\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.331758 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1252\n",
            "[LightGBM] [Info] Number of data points in the train set: 3006436, number of used features: 54\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.049522 -> initscore=-2.954553\n",
            "[LightGBM] [Info] Start training from score -2.954553\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-09-07 22:04:29,247] Trial 0 finished with value: 0.0 and parameters: {'num_leaves': 110, 'max_depth': 1, 'learning_rate': 0.04665435979160618, 'n_estimators': 24, 'subsample': 0.7695921103985472, 'colsample_bytree': 0.5092636851981066}. Best is trial 0 with value: 0.0.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 148884, number of negative: 2857552\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.426766 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1252\n",
            "[LightGBM] [Info] Number of data points in the train set: 3006436, number of used features: 54\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.049522 -> initscore=-2.954553\n",
            "[LightGBM] [Info] Start training from score -2.954553\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-09-07 22:05:23,184] Trial 1 finished with value: 0.4954100100019296 and parameters: {'num_leaves': 42, 'max_depth': 22, 'learning_rate': 0.07040347568522215, 'n_estimators': 59, 'subsample': 0.8605141541312862, 'colsample_bytree': 0.7852932961160316}. Best is trial 1 with value: 0.4954100100019296.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 148884, number of negative: 2857552\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.315887 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1252\n",
            "[LightGBM] [Info] Number of data points in the train set: 3006436, number of used features: 54\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.049522 -> initscore=-2.954553\n",
            "[LightGBM] [Info] Start training from score -2.954553\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-09-07 22:05:52,053] Trial 2 finished with value: 0.3435964848437707 and parameters: {'num_leaves': 39, 'max_depth': 11, 'learning_rate': 0.04501381496326246, 'n_estimators': 34, 'subsample': 0.5883872426330732, 'colsample_bytree': 0.5520327730254913}. Best is trial 1 with value: 0.4954100100019296.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 148884, number of negative: 2857552\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.453190 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1252\n",
            "[LightGBM] [Info] Number of data points in the train set: 3006436, number of used features: 54\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.049522 -> initscore=-2.954553\n",
            "[LightGBM] [Info] Start training from score -2.954553\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-09-07 22:07:12,153] Trial 3 finished with value: 0.3751392912500508 and parameters: {'num_leaves': 98, 'max_depth': 11, 'learning_rate': 0.014081233679489345, 'n_estimators': 83, 'subsample': 0.6657278074731843, 'colsample_bytree': 0.8611289841204062}. Best is trial 1 with value: 0.4954100100019296.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 148884, number of negative: 2857552\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.405679 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1252\n",
            "[LightGBM] [Info] Number of data points in the train set: 3006436, number of used features: 54\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.049522 -> initscore=-2.954553\n",
            "[LightGBM] [Info] Start training from score -2.954553\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-09-07 22:07:41,175] Trial 4 finished with value: 0.4732996141778475 and parameters: {'num_leaves': 131, 'max_depth': 22, 'learning_rate': 0.09098644264820112, 'n_estimators': 29, 'subsample': 0.9446418380136525, 'colsample_bytree': 0.5246107204350607}. Best is trial 1 with value: 0.4954100100019296.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 148884, number of negative: 2857552\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.427167 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1252\n",
            "[LightGBM] [Info] Number of data points in the train set: 3006436, number of used features: 54\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.049522 -> initscore=-2.954553\n",
            "[LightGBM] [Info] Start training from score -2.954553\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-09-07 22:08:41,056] Trial 5 finished with value: 0.2678124763616096 and parameters: {'num_leaves': 130, 'max_depth': 0, 'learning_rate': 0.015541354823367427, 'n_estimators': 56, 'subsample': 0.721933023028055, 'colsample_bytree': 0.8030280487280539}. Best is trial 1 with value: 0.4954100100019296.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 148884, number of negative: 2857552\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.680983 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1252\n",
            "[LightGBM] [Info] Number of data points in the train set: 3006436, number of used features: 54\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.049522 -> initscore=-2.954553\n",
            "[LightGBM] [Info] Start training from score -2.954553\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-09-07 22:10:23,350] Trial 6 finished with value: 0.5046460006581245 and parameters: {'num_leaves': 135, 'max_depth': 27, 'learning_rate': 0.03015336178654314, 'n_estimators': 95, 'subsample': 0.6929379237322278, 'colsample_bytree': 0.863495223787241}. Best is trial 6 with value: 0.5046460006581245.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 148884, number of negative: 2857552\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.682040 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1252\n",
            "[LightGBM] [Info] Number of data points in the train set: 3006436, number of used features: 54\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.049522 -> initscore=-2.954553\n",
            "[LightGBM] [Info] Start training from score -2.954553\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-09-07 22:11:38,285] Trial 7 finished with value: 0.5237023217523016 and parameters: {'num_leaves': 119, 'max_depth': 16, 'learning_rate': 0.06229030047083742, 'n_estimators': 68, 'subsample': 0.890847220762397, 'colsample_bytree': 0.8499040933639068}. Best is trial 7 with value: 0.5237023217523016.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 148884, number of negative: 2857552\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.399527 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1252\n",
            "[LightGBM] [Info] Number of data points in the train set: 3006436, number of used features: 54\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.049522 -> initscore=-2.954553\n",
            "[LightGBM] [Info] Start training from score -2.954553\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-09-07 22:12:07,590] Trial 8 finished with value: 0.28633173449045746 and parameters: {'num_leaves': 110, 'max_depth': 2, 'learning_rate': 0.0639857979278736, 'n_estimators': 68, 'subsample': 0.7753067636214088, 'colsample_bytree': 0.691415367249377}. Best is trial 7 with value: 0.5237023217523016.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 148884, number of negative: 2857552\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.506648 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1252\n",
            "[LightGBM] [Info] Number of data points in the train set: 3006436, number of used features: 54\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.049522 -> initscore=-2.954553\n",
            "[LightGBM] [Info] Start training from score -2.954553\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-09-07 22:12:32,787] Trial 9 finished with value: 0.2270975426644161 and parameters: {'num_leaves': 59, 'max_depth': 6, 'learning_rate': 0.03312587862436182, 'n_estimators': 25, 'subsample': 0.9874538621748712, 'colsample_bytree': 0.8950411083120052}. Best is trial 7 with value: 0.5237023217523016.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 148884, number of negative: 2857552\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.525660 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1252\n",
            "[LightGBM] [Info] Number of data points in the train set: 3006436, number of used features: 54\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.049522 -> initscore=-2.954553\n",
            "[LightGBM] [Info] Start training from score -2.954553\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-09-07 22:13:21,674] Trial 10 finished with value: 0.5036747700788264 and parameters: {'num_leaves': 73, 'max_depth': 19, 'learning_rate': 0.08800984514334438, 'n_estimators': 46, 'subsample': 0.8955740224970792, 'colsample_bytree': 0.9975851618392695}. Best is trial 7 with value: 0.5237023217523016.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 148884, number of negative: 2857552\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.500291 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1252\n",
            "[LightGBM] [Info] Number of data points in the train set: 3006436, number of used features: 54\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.049522 -> initscore=-2.954553\n",
            "[LightGBM] [Info] Start training from score -2.954553\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-09-07 22:15:07,289] Trial 11 finished with value: 0.5092748974268306 and parameters: {'num_leaves': 144, 'max_depth': 30, 'learning_rate': 0.0304848335778432, 'n_estimators': 98, 'subsample': 0.5215696678516148, 'colsample_bytree': 0.9478041179012795}. Best is trial 7 with value: 0.5237023217523016.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 148884, number of negative: 2857552\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.470879 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1252\n",
            "[LightGBM] [Info] Number of data points in the train set: 3006436, number of used features: 54\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.049522 -> initscore=-2.954553\n",
            "[LightGBM] [Info] Start training from score -2.954553\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-09-07 22:16:45,008] Trial 12 finished with value: 0.5350628912728176 and parameters: {'num_leaves': 150, 'max_depth': 30, 'learning_rate': 0.0725891144091528, 'n_estimators': 100, 'subsample': 0.5056544749922685, 'colsample_bytree': 0.979474197308235}. Best is trial 12 with value: 0.5350628912728176.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 148884, number of negative: 2857552\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.390147 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1252\n",
            "[LightGBM] [Info] Number of data points in the train set: 3006436, number of used features: 54\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.049522 -> initscore=-2.954553\n",
            "[LightGBM] [Info] Start training from score -2.954553\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-09-07 22:18:11,671] Trial 13 finished with value: 0.5335323373891188 and parameters: {'num_leaves': 146, 'max_depth': 17, 'learning_rate': 0.07472078188782408, 'n_estimators': 78, 'subsample': 0.8375146651490033, 'colsample_bytree': 0.6667348006746951}. Best is trial 12 with value: 0.5350628912728176.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 148884, number of negative: 2857552\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.398064 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1252\n",
            "[LightGBM] [Info] Number of data points in the train set: 3006436, number of used features: 54\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.049522 -> initscore=-2.954553\n",
            "[LightGBM] [Info] Start training from score -2.954553\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-09-07 22:19:43,901] Trial 14 finished with value: 0.5314553276155024 and parameters: {'num_leaves': 149, 'max_depth': 25, 'learning_rate': 0.07306206307671242, 'n_estimators': 83, 'subsample': 0.8341084692713856, 'colsample_bytree': 0.6902743644293171}. Best is trial 12 with value: 0.5350628912728176.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 148884, number of negative: 2857552\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.383533 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1252\n",
            "[LightGBM] [Info] Number of data points in the train set: 3006436, number of used features: 54\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.049522 -> initscore=-2.954553\n",
            "[LightGBM] [Info] Start training from score -2.954553\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-09-07 22:21:03,157] Trial 15 finished with value: 0.5211851883907953 and parameters: {'num_leaves': 81, 'max_depth': 14, 'learning_rate': 0.07986855553636288, 'n_estimators': 85, 'subsample': 0.6188452031926133, 'colsample_bytree': 0.6047855085348777}. Best is trial 12 with value: 0.5350628912728176.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 148884, number of negative: 2857552\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 1.763947 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1252\n",
            "[LightGBM] [Info] Number of data points in the train set: 3006436, number of used features: 54\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.049522 -> initscore=-2.954553\n",
            "[LightGBM] [Info] Start training from score -2.954553\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-09-07 22:21:56,571] Trial 16 finished with value: 0.49276178761654976 and parameters: {'num_leaves': 23, 'max_depth': 30, 'learning_rate': 0.09730297770004756, 'n_estimators': 73, 'subsample': 0.532745400581323, 'colsample_bytree': 0.6917305473435659}. Best is trial 12 with value: 0.5350628912728176.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 148884, number of negative: 2857552\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.382639 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1252\n",
            "[LightGBM] [Info] Number of data points in the train set: 3006436, number of used features: 54\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.049522 -> initscore=-2.954553\n",
            "[LightGBM] [Info] Start training from score -2.954553\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-09-07 22:23:21,351] Trial 17 finished with value: 0.520966220159487 and parameters: {'num_leaves': 150, 'max_depth': 8, 'learning_rate': 0.07940215610990047, 'n_estimators': 90, 'subsample': 0.8048343777756106, 'colsample_bytree': 0.6300038426872249}. Best is trial 12 with value: 0.5350628912728176.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 148884, number of negative: 2857552\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.420764 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1252\n",
            "[LightGBM] [Info] Number of data points in the train set: 3006436, number of used features: 54\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.049522 -> initscore=-2.954553\n",
            "[LightGBM] [Info] Start training from score -2.954553\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-09-07 22:25:05,714] Trial 18 finished with value: 0.5265673882691934 and parameters: {'num_leaves': 120, 'max_depth': 18, 'learning_rate': 0.05403173057071387, 'n_estimators': 100, 'subsample': 0.6178092172639945, 'colsample_bytree': 0.7316724947740405}. Best is trial 12 with value: 0.5350628912728176.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 148884, number of negative: 2857552\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.396774 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1252\n",
            "[LightGBM] [Info] Number of data points in the train set: 3006436, number of used features: 54\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.049522 -> initscore=-2.954553\n",
            "[LightGBM] [Info] Start training from score -2.954553\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-09-07 22:26:21,799] Trial 19 finished with value: 0.5230926645279981 and parameters: {'num_leaves': 97, 'max_depth': 24, 'learning_rate': 0.08164376295139472, 'n_estimators': 73, 'subsample': 0.7159492240004055, 'colsample_bytree': 0.6430953884435167}. Best is trial 12 with value: 0.5350628912728176.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 148884, number of negative: 2857552\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.419478 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1252\n",
            "[LightGBM] [Info] Number of data points in the train set: 3006436, number of used features: 54\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.049522 -> initscore=-2.954553\n",
            "[LightGBM] [Info] Start training from score -2.954553\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-09-07 22:27:44,962] Trial 20 finished with value: 0.5246366177237536 and parameters: {'num_leaves': 134, 'max_depth': 27, 'learning_rate': 0.05940170496071944, 'n_estimators': 76, 'subsample': 0.5734776025148978, 'colsample_bytree': 0.766570882824184}. Best is trial 12 with value: 0.5350628912728176.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 148884, number of negative: 2857552\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.405646 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1252\n",
            "[LightGBM] [Info] Number of data points in the train set: 3006436, number of used features: 54\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.049522 -> initscore=-2.954553\n",
            "[LightGBM] [Info] Start training from score -2.954553\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-09-07 22:29:16,464] Trial 21 finished with value: 0.5348619921063791 and parameters: {'num_leaves': 149, 'max_depth': 25, 'learning_rate': 0.07462635790771016, 'n_estimators': 84, 'subsample': 0.8303892189450517, 'colsample_bytree': 0.6856033046970633}. Best is trial 12 with value: 0.5350628912728176.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 148884, number of negative: 2857552\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.315903 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1252\n",
            "[LightGBM] [Info] Number of data points in the train set: 3006436, number of used features: 54\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.049522 -> initscore=-2.954553\n",
            "[LightGBM] [Info] Start training from score -2.954553\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-09-07 22:30:37,718] Trial 22 finished with value: 0.5317843546624181 and parameters: {'num_leaves': 140, 'max_depth': 20, 'learning_rate': 0.07250129156310922, 'n_estimators': 91, 'subsample': 0.8207952823787049, 'colsample_bytree': 0.5788173270388811}. Best is trial 12 with value: 0.5350628912728176.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 148884, number of negative: 2857552\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.416915 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1252\n",
            "[LightGBM] [Info] Number of data points in the train set: 3006436, number of used features: 54\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.049522 -> initscore=-2.954553\n",
            "[LightGBM] [Info] Start training from score -2.954553\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-09-07 22:32:10,800] Trial 23 finished with value: 0.5317218269999301 and parameters: {'num_leaves': 123, 'max_depth': 27, 'learning_rate': 0.06904671426237913, 'n_estimators': 88, 'subsample': 0.9276647690914339, 'colsample_bytree': 0.7236060771036227}. Best is trial 12 with value: 0.5350628912728176.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 148884, number of negative: 2857552\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.399247 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1252\n",
            "[LightGBM] [Info] Number of data points in the train set: 3006436, number of used features: 54\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.049522 -> initscore=-2.954553\n",
            "[LightGBM] [Info] Start training from score -2.954553\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-09-07 22:33:37,341] Trial 24 finished with value: 0.5381899173122265 and parameters: {'num_leaves': 149, 'max_depth': 24, 'learning_rate': 0.08847877238689464, 'n_estimators': 80, 'subsample': 0.8601882473816211, 'colsample_bytree': 0.6639178583135487}. Best is trial 24 with value: 0.5381899173122265.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 148884, number of negative: 2857552\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.443888 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1252\n",
            "[LightGBM] [Info] Number of data points in the train set: 3006436, number of used features: 54\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.049522 -> initscore=-2.954553\n",
            "[LightGBM] [Info] Start training from score -2.954553\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-09-07 22:34:32,239] Trial 25 finished with value: 0.520068085258249 and parameters: {'num_leaves': 106, 'max_depth': 30, 'learning_rate': 0.08812918771531045, 'n_estimators': 50, 'subsample': 0.7877882774173365, 'colsample_bytree': 0.823305386604873}. Best is trial 24 with value: 0.5381899173122265.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 148884, number of negative: 2857552\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.411119 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1252\n",
            "[LightGBM] [Info] Number of data points in the train set: 3006436, number of used features: 54\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.049522 -> initscore=-2.954553\n",
            "[LightGBM] [Info] Start training from score -2.954553\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-09-07 22:36:02,699] Trial 26 finished with value: 0.5413397794086484 and parameters: {'num_leaves': 125, 'max_depth': 24, 'learning_rate': 0.09965662548937204, 'n_estimators': 96, 'subsample': 0.8779686128434079, 'colsample_bytree': 0.7452699761318937}. Best is trial 26 with value: 0.5413397794086484.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 148884, number of negative: 2857552\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.461978 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1252\n",
            "[LightGBM] [Info] Number of data points in the train set: 3006436, number of used features: 54\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.049522 -> initscore=-2.954553\n",
            "[LightGBM] [Info] Start training from score -2.954553\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-09-07 22:37:28,633] Trial 27 finished with value: 0.5361862000461813 and parameters: {'num_leaves': 125, 'max_depth': 22, 'learning_rate': 0.09450432275372428, 'n_estimators': 95, 'subsample': 0.9946730388894407, 'colsample_bytree': 0.9376191797961411}. Best is trial 26 with value: 0.5413397794086484.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 148884, number of negative: 2857552\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.461376 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1252\n",
            "[LightGBM] [Info] Number of data points in the train set: 3006436, number of used features: 54\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.049522 -> initscore=-2.954553\n",
            "[LightGBM] [Info] Start training from score -2.954553\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-09-07 22:38:47,795] Trial 28 finished with value: 0.5297733818202398 and parameters: {'num_leaves': 92, 'max_depth': 22, 'learning_rate': 0.09708688324824108, 'n_estimators': 91, 'subsample': 0.9962473697247536, 'colsample_bytree': 0.925389738418493}. Best is trial 26 with value: 0.5413397794086484.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 148884, number of negative: 2857552\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.425993 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1252\n",
            "[LightGBM] [Info] Number of data points in the train set: 3006436, number of used features: 54\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.049522 -> initscore=-2.954553\n",
            "[LightGBM] [Info] Start training from score -2.954553\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-09-07 22:40:14,728] Trial 29 finished with value: 0.5361694387450318 and parameters: {'num_leaves': 111, 'max_depth': 14, 'learning_rate': 0.0995645178778326, 'n_estimators': 94, 'subsample': 0.9648035147923388, 'colsample_bytree': 0.7577899360218158}. Best is trial 26 with value: 0.5413397794086484.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 148884, number of negative: 2857552\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.435460 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1252\n",
            "[LightGBM] [Info] Number of data points in the train set: 3006436, number of used features: 54\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.049522 -> initscore=-2.954553\n",
            "[LightGBM] [Info] Start training from score -2.954553\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-09-07 22:41:23,930] Trial 30 finished with value: 0.5307413580464374 and parameters: {'num_leaves': 117, 'max_depth': 23, 'learning_rate': 0.0917038945502325, 'n_estimators': 65, 'subsample': 0.9122445651001845, 'colsample_bytree': 0.8262904755529576}. Best is trial 26 with value: 0.5413397794086484.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 148884, number of negative: 2857552\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 1.449109 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1252\n",
            "[LightGBM] [Info] Number of data points in the train set: 3006436, number of used features: 54\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.049522 -> initscore=-2.954553\n",
            "[LightGBM] [Info] Start training from score -2.954553\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-09-07 22:43:00,443] Trial 31 finished with value: 0.532902591895751 and parameters: {'num_leaves': 108, 'max_depth': 15, 'learning_rate': 0.0997324759102568, 'n_estimators': 94, 'subsample': 0.9592042076644465, 'colsample_bytree': 0.7500461946598118}. Best is trial 26 with value: 0.5413397794086484.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 148884, number of negative: 2857552\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.426890 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1252\n",
            "[LightGBM] [Info] Number of data points in the train set: 3006436, number of used features: 54\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.049522 -> initscore=-2.954553\n",
            "[LightGBM] [Info] Start training from score -2.954553\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-09-07 22:44:22,531] Trial 32 finished with value: 0.5341144695032948 and parameters: {'num_leaves': 126, 'max_depth': 20, 'learning_rate': 0.08509606983586714, 'n_estimators': 80, 'subsample': 0.8739779777685737, 'colsample_bytree': 0.7796142428496466}. Best is trial 26 with value: 0.5413397794086484.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 148884, number of negative: 2857552\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.411616 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1252\n",
            "[LightGBM] [Info] Number of data points in the train set: 3006436, number of used features: 54\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.049522 -> initscore=-2.954553\n",
            "[LightGBM] [Info] Start training from score -2.954553\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-09-07 22:45:50,751] Trial 33 finished with value: 0.5349150478501551 and parameters: {'num_leaves': 112, 'max_depth': 12, 'learning_rate': 0.09404801064512351, 'n_estimators': 94, 'subsample': 0.9632031678020174, 'colsample_bytree': 0.7227152026988908}. Best is trial 26 with value: 0.5413397794086484.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 148884, number of negative: 2857552\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.392037 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1252\n",
            "[LightGBM] [Info] Number of data points in the train set: 3006436, number of used features: 54\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.049522 -> initscore=-2.954553\n",
            "[LightGBM] [Info] Start training from score -2.954553\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-09-07 22:47:20,615] Trial 34 finished with value: 0.5373717742540675 and parameters: {'num_leaves': 137, 'max_depth': 21, 'learning_rate': 0.09384612858710749, 'n_estimators': 87, 'subsample': 0.8649561811984362, 'colsample_bytree': 0.6425370461770894}. Best is trial 26 with value: 0.5413397794086484.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 148884, number of negative: 2857552\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.315779 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1252\n",
            "[LightGBM] [Info] Number of data points in the train set: 3006436, number of used features: 54\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.049522 -> initscore=-2.954553\n",
            "[LightGBM] [Info] Start training from score -2.954553\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-09-07 22:48:35,407] Trial 35 finished with value: 0.5341624092324224 and parameters: {'num_leaves': 138, 'max_depth': 22, 'learning_rate': 0.08354534532145917, 'n_estimators': 87, 'subsample': 0.8622929378649183, 'colsample_bytree': 0.5880497031323718}. Best is trial 26 with value: 0.5413397794086484.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 148884, number of negative: 2857552\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.412021 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1252\n",
            "[LightGBM] [Info] Number of data points in the train set: 3006436, number of used features: 54\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.049522 -> initscore=-2.954553\n",
            "[LightGBM] [Info] Start training from score -2.954553\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-09-07 22:50:01,520] Trial 36 finished with value: 0.5335569447202544 and parameters: {'num_leaves': 127, 'max_depth': 20, 'learning_rate': 0.09225040766908765, 'n_estimators': 80, 'subsample': 0.7530860775779535, 'colsample_bytree': 0.6391775509373191}. Best is trial 26 with value: 0.5413397794086484.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 148884, number of negative: 2857552\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.424046 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1252\n",
            "[LightGBM] [Info] Number of data points in the train set: 3006436, number of used features: 54\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.049522 -> initscore=-2.954553\n",
            "[LightGBM] [Info] Start training from score -2.954553\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-09-07 22:50:37,154] Trial 37 finished with value: 0.49075247899180074 and parameters: {'num_leaves': 139, 'max_depth': 26, 'learning_rate': 0.08765243409562973, 'n_estimators': 39, 'subsample': 0.9213582440476777, 'colsample_bytree': 0.5044610378819137}. Best is trial 26 with value: 0.5413397794086484.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 148884, number of negative: 2857552\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.337843 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1252\n",
            "[LightGBM] [Info] Number of data points in the train set: 3006436, number of used features: 54\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.049522 -> initscore=-2.954553\n",
            "[LightGBM] [Info] Start training from score -2.954553\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-09-07 22:51:29,557] Trial 38 finished with value: 0.5205181935149557 and parameters: {'num_leaves': 133, 'max_depth': 22, 'learning_rate': 0.09399565799331132, 'n_estimators': 60, 'subsample': 0.8651105473958973, 'colsample_bytree': 0.534826415579813}. Best is trial 26 with value: 0.5413397794086484.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 148884, number of negative: 2857552\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.308099 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1252\n",
            "[LightGBM] [Info] Number of data points in the train set: 3006436, number of used features: 54\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.049522 -> initscore=-2.954553\n",
            "[LightGBM] [Info] Start training from score -2.954553\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-09-07 22:52:48,961] Trial 39 finished with value: 0.5090391927752445 and parameters: {'num_leaves': 103, 'max_depth': 28, 'learning_rate': 0.04211929494193901, 'n_estimators': 97, 'subsample': 0.8922480359519097, 'colsample_bytree': 0.5626372751219899}. Best is trial 26 with value: 0.5413397794086484.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 148884, number of negative: 2857552\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 1.916797 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1252\n",
            "[LightGBM] [Info] Number of data points in the train set: 3006436, number of used features: 54\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.049522 -> initscore=-2.954553\n",
            "[LightGBM] [Info] Start training from score -2.954553\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-09-07 22:54:09,051] Trial 40 finished with value: 0.5338540296061135 and parameters: {'num_leaves': 130, 'max_depth': 24, 'learning_rate': 0.09580985870853065, 'n_estimators': 74, 'subsample': 0.7939808416597732, 'colsample_bytree': 0.6605200849190624}. Best is trial 26 with value: 0.5413397794086484.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 148884, number of negative: 2857552\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.380913 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1252\n",
            "[LightGBM] [Info] Number of data points in the train set: 3006436, number of used features: 54\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.049522 -> initscore=-2.954553\n",
            "[LightGBM] [Info] Start training from score -2.954553\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-09-07 22:55:36,335] Trial 41 finished with value: 0.5337505516383387 and parameters: {'num_leaves': 114, 'max_depth': 13, 'learning_rate': 0.09944726555777801, 'n_estimators': 93, 'subsample': 0.9653868174242549, 'colsample_bytree': 0.6165983677562559}. Best is trial 26 with value: 0.5413397794086484.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 148884, number of negative: 2857552\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.670387 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1252\n",
            "[LightGBM] [Info] Number of data points in the train set: 3006436, number of used features: 54\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.049522 -> initscore=-2.954553\n",
            "[LightGBM] [Info] Start training from score -2.954553\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-09-07 22:56:59,790] Trial 42 finished with value: 0.5365070162369693 and parameters: {'num_leaves': 123, 'max_depth': 18, 'learning_rate': 0.08877783297866153, 'n_estimators': 88, 'subsample': 0.9461710852524068, 'colsample_bytree': 0.8829863034879264}. Best is trial 26 with value: 0.5413397794086484.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 148884, number of negative: 2857552\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.458134 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1252\n",
            "[LightGBM] [Info] Number of data points in the train set: 3006436, number of used features: 54\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.049522 -> initscore=-2.954553\n",
            "[LightGBM] [Info] Start training from score -2.954553\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-09-07 22:58:26,812] Trial 43 finished with value: 0.5417509096912376 and parameters: {'num_leaves': 141, 'max_depth': 18, 'learning_rate': 0.0898623914049592, 'n_estimators': 88, 'subsample': 0.9394283269044714, 'colsample_bytree': 0.9097759487542745}. Best is trial 43 with value: 0.5417509096912376.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 148884, number of negative: 2857552\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.545675 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1252\n",
            "[LightGBM] [Info] Number of data points in the train set: 3006436, number of used features: 54\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.049522 -> initscore=-2.954553\n",
            "[LightGBM] [Info] Start training from score -2.954553\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-09-07 22:59:52,795] Trial 44 finished with value: 0.5403645237391166 and parameters: {'num_leaves': 142, 'max_depth': 18, 'learning_rate': 0.08866861976777299, 'n_estimators': 88, 'subsample': 0.9253045672933954, 'colsample_bytree': 0.8861831128080011}. Best is trial 43 with value: 0.5417509096912376.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 148884, number of negative: 2857552\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.706947 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1252\n",
            "[LightGBM] [Info] Number of data points in the train set: 3006436, number of used features: 54\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.049522 -> initscore=-2.954553\n",
            "[LightGBM] [Info] Start training from score -2.954553\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-09-07 23:01:17,279] Trial 45 finished with value: 0.5368199823946174 and parameters: {'num_leaves': 142, 'max_depth': 16, 'learning_rate': 0.07821715043901568, 'n_estimators': 80, 'subsample': 0.9077480189257079, 'colsample_bytree': 0.9068717257143546}. Best is trial 43 with value: 0.5417509096912376.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 148884, number of negative: 2857552\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.449546 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1252\n",
            "[LightGBM] [Info] Number of data points in the train set: 3006436, number of used features: 54\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.049522 -> initscore=-2.954553\n",
            "[LightGBM] [Info] Start training from score -2.954553\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-09-07 23:02:27,911] Trial 46 finished with value: 0.0 and parameters: {'num_leaves': 143, 'max_depth': 19, 'learning_rate': 0.010254320406453472, 'n_estimators': 67, 'subsample': 0.9282581605217852, 'colsample_bytree': 0.8636308000815527}. Best is trial 43 with value: 0.5417509096912376.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 148884, number of negative: 2857552\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.518167 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1252\n",
            "[LightGBM] [Info] Number of data points in the train set: 3006436, number of used features: 54\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.049522 -> initscore=-2.954553\n",
            "[LightGBM] [Info] Start training from score -2.954553\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-09-07 23:03:57,002] Trial 47 finished with value: 0.5314220777642306 and parameters: {'num_leaves': 135, 'max_depth': 21, 'learning_rate': 0.0676265852136463, 'n_estimators': 86, 'subsample': 0.8781784868718445, 'colsample_bytree': 0.9666324532020054}. Best is trial 43 with value: 0.5417509096912376.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 148884, number of negative: 2857552\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 1.536464 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1252\n",
            "[LightGBM] [Info] Number of data points in the train set: 3006436, number of used features: 54\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.049522 -> initscore=-2.954553\n",
            "[LightGBM] [Info] Start training from score -2.954553\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-09-07 23:05:19,357] Trial 48 finished with value: 0.517997445349591 and parameters: {'num_leaves': 61, 'max_depth': 10, 'learning_rate': 0.08496808199935389, 'n_estimators': 82, 'subsample': 0.8512128078781721, 'colsample_bytree': 0.8196758849649648}. Best is trial 43 with value: 0.5417509096912376.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 148884, number of negative: 2857552\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.438453 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1252\n",
            "[LightGBM] [Info] Number of data points in the train set: 3006436, number of used features: 54\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.049522 -> initscore=-2.954553\n",
            "[LightGBM] [Info] Start training from score -2.954553\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-09-07 23:06:35,595] Trial 49 finished with value: 0.53722906763715 and parameters: {'num_leaves': 142, 'max_depth': 17, 'learning_rate': 0.09008181985910747, 'n_estimators': 71, 'subsample': 0.8936023940973493, 'colsample_bytree': 0.7884999094969503}. Best is trial 43 with value: 0.5417509096912376.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best parameters for LightGBM: {'num_leaves': 141, 'max_depth': 18, 'learning_rate': 0.0898623914049592, 'n_estimators': 88, 'subsample': 0.9394283269044714, 'colsample_bytree': 0.9097759487542745}\n",
            "Best MCC score for LightGBM: 0.5417509096912376\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lgbm_best_params = {'num_leaves': 141, 'max_depth': 18, 'learning_rate': 0.0898623914049592, 'n_estimators': 88, 'subsample': 0.9394283269044714, 'colsample_bytree': 0.9097759487542745}"
      ],
      "metadata": {
        "id": "RP94pafKvovT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def objective_xgb(trial):\n",
        "    params = {\n",
        "        'objective': 'binary:logistic',\n",
        "        'eval_metric': 'logloss',\n",
        "        'max_depth': trial.suggest_int('max_depth', 1, 10),\n",
        "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3),\n",
        "        'n_estimators': trial.suggest_int('n_estimators', 20, 100),\n",
        "        'subsample': trial.suggest_float('subsample', 0.5, 1.0),\n",
        "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),\n",
        "    }\n",
        "\n",
        "    model = XGBClassifier(**params)\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    preds = model.predict(X_test)\n",
        "    mcc = matthews_corrcoef(y_test, preds)\n",
        "    return mcc\n",
        "\n",
        "# Оптимизация гиперпараметров XGBoost\n",
        "xgb_study = optuna.create_study(direction='maximize')\n",
        "xgb_study.optimize(objective_xgb, n_trials=50)\n",
        "\n",
        "print(\"Best parameters for XGBoost:\", xgb_study.best_params)\n",
        "print(\"Best MCC score for XGBoost:\", xgb_study.best_value)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S1fq88fznUIp",
        "outputId": "50b14058-ebab-499e-d025-000b2107b134"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-09-07 23:06:35,622] A new study created in memory with name: no-name-e9501b3f-2bab-4359-bcb9-d8f250a3a26f\n",
            "[I 2024-09-07 23:07:03,072] Trial 0 finished with value: 0.49065098579628613 and parameters: {'max_depth': 6, 'learning_rate': 0.15355381575759622, 'n_estimators': 36, 'subsample': 0.5311407353244333, 'colsample_bytree': 0.59982035326213}. Best is trial 0 with value: 0.49065098579628613.\n",
            "[I 2024-09-07 23:07:52,348] Trial 1 finished with value: 0.5459055809276583 and parameters: {'max_depth': 9, 'learning_rate': 0.16983101942399112, 'n_estimators': 58, 'subsample': 0.6297069828729402, 'colsample_bytree': 0.7596211231073581}. Best is trial 1 with value: 0.5459055809276583.\n",
            "[I 2024-09-07 23:08:31,623] Trial 2 finished with value: 0.3552392782782319 and parameters: {'max_depth': 3, 'learning_rate': 0.05478793017356273, 'n_estimators': 86, 'subsample': 0.8933938338208862, 'colsample_bytree': 0.8171611685660667}. Best is trial 1 with value: 0.5459055809276583.\n",
            "[I 2024-09-07 23:09:01,192] Trial 3 finished with value: 0.20121475965960575 and parameters: {'max_depth': 1, 'learning_rate': 0.18192982810954308, 'n_estimators': 98, 'subsample': 0.8999709856886449, 'colsample_bytree': 0.8625092637673342}. Best is trial 1 with value: 0.5459055809276583.\n",
            "[I 2024-09-07 23:09:43,923] Trial 4 finished with value: 0.4843540582360212 and parameters: {'max_depth': 4, 'learning_rate': 0.10170218875297317, 'n_estimators': 98, 'subsample': 0.8347957035122658, 'colsample_bytree': 0.6908274549957761}. Best is trial 1 with value: 0.5459055809276583.\n",
            "[I 2024-09-07 23:10:35,883] Trial 5 finished with value: 0.5521107608737487 and parameters: {'max_depth': 10, 'learning_rate': 0.209670762741193, 'n_estimators': 67, 'subsample': 0.9170878312749212, 'colsample_bytree': 0.6928153979536702}. Best is trial 5 with value: 0.5521107608737487.\n",
            "[I 2024-09-07 23:11:08,754] Trial 6 finished with value: 0.3836813715055485 and parameters: {'max_depth': 2, 'learning_rate': 0.14616916357297913, 'n_estimators': 90, 'subsample': 0.5795509715589426, 'colsample_bytree': 0.9377518010582089}. Best is trial 5 with value: 0.5521107608737487.\n",
            "[I 2024-09-07 23:11:39,570] Trial 7 finished with value: 0.5356865771851266 and parameters: {'max_depth': 10, 'learning_rate': 0.12858740936381552, 'n_estimators': 28, 'subsample': 0.5220410324509002, 'colsample_bytree': 0.9530335387325378}. Best is trial 5 with value: 0.5521107608737487.\n",
            "[I 2024-09-07 23:12:21,036] Trial 8 finished with value: 0.49301501738859943 and parameters: {'max_depth': 5, 'learning_rate': 0.13145993152756533, 'n_estimators': 80, 'subsample': 0.8513204019314144, 'colsample_bytree': 0.7318998037931951}. Best is trial 5 with value: 0.5521107608737487.\n",
            "[I 2024-09-07 23:12:41,869] Trial 9 finished with value: 0.18243554314060162 and parameters: {'max_depth': 1, 'learning_rate': 0.28226040174907874, 'n_estimators': 50, 'subsample': 0.9585446395458975, 'colsample_bytree': 0.5533861910100296}. Best is trial 5 with value: 0.5521107608737487.\n",
            "[I 2024-09-07 23:13:30,833] Trial 10 finished with value: 0.5441479692283018 and parameters: {'max_depth': 8, 'learning_rate': 0.24065463013102198, 'n_estimators': 72, 'subsample': 0.6963609571061019, 'colsample_bytree': 0.6313521707017142}. Best is trial 5 with value: 0.5521107608737487.\n",
            "[I 2024-09-07 23:14:22,619] Trial 11 finished with value: 0.5553648687773225 and parameters: {'max_depth': 10, 'learning_rate': 0.20695382802107634, 'n_estimators': 61, 'subsample': 0.6887593656639797, 'colsample_bytree': 0.7947546560998784}. Best is trial 11 with value: 0.5553648687773225.\n",
            "[I 2024-09-07 23:15:03,195] Trial 12 finished with value: 0.5308927897617054 and parameters: {'max_depth': 7, 'learning_rate': 0.22322184785746346, 'n_estimators': 65, 'subsample': 0.753448748096804, 'colsample_bytree': 0.8062912164964464}. Best is trial 11 with value: 0.5553648687773225.\n",
            "[I 2024-09-07 23:15:46,701] Trial 13 finished with value: 0.5507302740121409 and parameters: {'max_depth': 10, 'learning_rate': 0.2122624343026022, 'n_estimators': 47, 'subsample': 0.7515135634790141, 'colsample_bytree': 0.671071257538902}. Best is trial 11 with value: 0.5553648687773225.\n",
            "[I 2024-09-07 23:16:34,549] Trial 14 finished with value: 0.546188092812854 and parameters: {'max_depth': 8, 'learning_rate': 0.292587916633128, 'n_estimators': 72, 'subsample': 0.996392458208257, 'colsample_bytree': 0.8810709730516977}. Best is trial 11 with value: 0.5553648687773225.\n",
            "[I 2024-09-07 23:17:19,891] Trial 15 finished with value: 0.5550123465654956 and parameters: {'max_depth': 10, 'learning_rate': 0.25253154403156874, 'n_estimators': 55, 'subsample': 0.6975397801082236, 'colsample_bytree': 0.7464531392348414}. Best is trial 11 with value: 0.5553648687773225.\n",
            "[I 2024-09-07 23:18:00,990] Trial 16 finished with value: 0.5411997973042636 and parameters: {'max_depth': 8, 'learning_rate': 0.25964263253164505, 'n_estimators': 53, 'subsample': 0.6558395398111136, 'colsample_bytree': 0.7707599603558909}. Best is trial 11 with value: 0.5553648687773225.\n",
            "[I 2024-09-07 23:18:28,075] Trial 17 finished with value: 0.5097501862088347 and parameters: {'max_depth': 6, 'learning_rate': 0.25358026961485863, 'n_estimators': 39, 'subsample': 0.7966324877886215, 'colsample_bytree': 0.8756183929637538}. Best is trial 11 with value: 0.5553648687773225.\n",
            "[I 2024-09-07 23:19:04,990] Trial 18 finished with value: 0.5408553460662836 and parameters: {'max_depth': 9, 'learning_rate': 0.1879414812127234, 'n_estimators': 42, 'subsample': 0.6825698328742315, 'colsample_bytree': 0.8171276269701364}. Best is trial 11 with value: 0.5553648687773225.\n",
            "[I 2024-09-07 23:19:30,216] Trial 19 finished with value: 0.0 and parameters: {'max_depth': 9, 'learning_rate': 0.018360500872649593, 'n_estimators': 20, 'subsample': 0.608861856772701, 'colsample_bytree': 0.5144956874833897}. Best is trial 11 with value: 0.5553648687773225.\n",
            "[I 2024-09-07 23:20:13,657] Trial 20 finished with value: 0.5010418827511643 and parameters: {'max_depth': 7, 'learning_rate': 0.09540642582184033, 'n_estimators': 59, 'subsample': 0.7049969904458713, 'colsample_bytree': 0.7274375595707276}. Best is trial 11 with value: 0.5553648687773225.\n",
            "[I 2024-09-07 23:21:11,811] Trial 21 finished with value: 0.5546336086819262 and parameters: {'max_depth': 10, 'learning_rate': 0.22353071763681015, 'n_estimators': 74, 'subsample': 0.8015470157010742, 'colsample_bytree': 0.6642106546298376}. Best is trial 11 with value: 0.5553648687773225.\n",
            "[I 2024-09-07 23:22:10,187] Trial 22 finished with value: 0.5567993310696406 and parameters: {'max_depth': 10, 'learning_rate': 0.2700911397423918, 'n_estimators': 77, 'subsample': 0.7980149602309258, 'colsample_bytree': 0.6193194358238914}. Best is trial 22 with value: 0.5567993310696406.\n",
            "[I 2024-09-07 23:22:58,362] Trial 23 finished with value: 0.5467059022209547 and parameters: {'max_depth': 9, 'learning_rate': 0.2686513304950035, 'n_estimators': 62, 'subsample': 0.7318360798127245, 'colsample_bytree': 0.6059915573763568}. Best is trial 22 with value: 0.5567993310696406.\n",
            "[I 2024-09-07 23:23:57,569] Trial 24 finished with value: 0.5552907958409058 and parameters: {'max_depth': 10, 'learning_rate': 0.23719420868667515, 'n_estimators': 78, 'subsample': 0.7830312183528938, 'colsample_bytree': 0.5428607271065006}. Best is trial 22 with value: 0.5567993310696406.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# conv layers approach"
      ],
      "metadata": {
        "id": "56w5lJJY_Nm8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from torch.utils.data import DataLoader, TensorDataset\n"
      ],
      "metadata": {
        "id": "yDdbdlPlRF1_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Входные данные: произвольные размеры\n",
        "rgb_channels = torch.Tensor(train_data[train_data['date'] == '2021-06-06'][['red', 'green', 'blue']].values.reshape(1, 3, -1))\n",
        "ir_channel = torch.Tensor(train_data[train_data['date'] == '2021-06-06']['info_red'].values.reshape(1, -1))\n",
        "mask = torch.Tensor(train_data[train_data['date'] == '2021-06-06']['mask'].values.reshape(1, -1))     # Тензор IR (64 примера, длина 256)\n",
        "\n",
        " # Должно быть (64, 128)"
      ],
      "metadata": {
        "id": "OfYAn_QAGWYS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(rgb_channels.size(), ir_channel.size(), mask.size())"
      ],
      "metadata": {
        "id": "aqOhoiO0H0w4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rgb_channels"
      ],
      "metadata": {
        "id": "tVuAqu1tI4_U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = train_data[['blue', 'red', 'green', 'info_red']].values  # Все колонки, кроме последней\n",
        "y = train_data['mask'].values      # Последняя колонка\n",
        "\n",
        "# Стандартизация данных\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Разделение на обучающую и тестовую выборки\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Преобразование в тензоры\n",
        "X_train_tensor = torch.FloatTensor(X_train).permute(0, 1).view(4, -1)\n",
        "y_train_tensor = torch.FloatTensor(y_train).view(-1, 1)  # Приведение к форме (N, 1)\n",
        "X_test_tensor = torch.FloatTensor(X_test).view(4, -1)\n",
        "y_test_tensor = torch.FloatTensor(y_test).view(-1, 1)\n",
        "\n",
        "# Создание DataLoader\n",
        "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)"
      ],
      "metadata": {
        "id": "9P5_H0f-NJwP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_tensor"
      ],
      "metadata": {
        "id": "rjrH5FHMSpps"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SimpleCNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels=4, out_channels=8, kernel_size=2)\n",
        "        self.pool = nn.MaxPool1d(kernel_size=2)\n",
        "        self.conv2 = nn.Conv2d(in_channels=8, out_channels=16, kernel_size=2)\n",
        "        self.fc1 = nn.Linear(16 * 1, 32)  # Измените размер в зависимости от выходного размера после свертки и пуллинга\n",
        "        self.fc2 = nn.Linear(32, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(nn.ReLU(self.conv1(x)))\n",
        "        x = self.pool(nn.ReLU(self.conv2(x)))\n",
        "        x = x.view(-1, 16 * 1)  # Приведение к нужной форме (измените на правильный размер)\n",
        "        x = nn.ReLU(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "model = SimpleCNN()"
      ],
      "metadata": {
        "id": "x98kt_F_RQJK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()  # Для регрессии используем MSE\n",
        "optimizer = optim.AdamW(model.parameters(), lr=0.001)\n",
        "\n",
        "# Обучение\n",
        "num_epochs = 50\n",
        "for epoch in range(num_epochs):\n",
        "    for inputs, targets in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs.unsqueeze(1))  # Добавление размерности для Conv1d\n",
        "        loss = criterion(outputs, targets)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {loss.item():.4f}')"
      ],
      "metadata": {
        "id": "Yw6GvgGaRYq8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fL-fZvdDRjnv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}